# ML Lecture1 Note1
- [ML Lecture1 Note1](#ml-lecture1-note1)
    - [ML的应用](#ml的应用)
    - [ML的分类](#ml的分类)
    - [监督学习](#监督学习)
    - [无监督学习](#无监督学习)
    - [相关术语（terminology）🧐](#相关术语terminology)
    - [线性回归模型](#线性回归模型)
    - [代价函数（cost function）](#代价函数cost-function)

### ML的应用
ML除了生活中的基本应用，实际上还用到了工业、医疗等其他领域。ML的最大作用是处理一些复杂的问题，即不能**显式**通过程序直接解决的问题，而是需要机器自己学习来解决的问题。未来的目标是实现AGI(artificial general intelligence)，即极像人类的ai。
### ML的分类
监督学习(supervised learning)，非监督学习(unsupervised learning)和强化学习(reinforcement learning)。其中监督学习的运用最广泛，作用也最大。    

### 监督学习
![](2023-02-21-00-00-47.png)
如图，即通过给出输入x和输出y（即正确答案），机器能通过监督学习找到其中的映射，在只给出x的情况下推测出y的值。e.g.输入一些用户信息以及广告信息来推测用户是否会点击它，这是推荐算法的一种。  
其中，监督学习主要有回归和分类两个种类。两者的区别是回归算法中是从无数可能结果中进行预测，而分类算法只是从有限的可能结果进行猜测。此外，回归算法面对的是数字问题，而分类算法面对的对象则十分广泛（是一个个category）。

### 无监督学习
"Find something interesting in unlabeled data".我们没有试图监督算法（即没有给出正确的样本结果y），而是让算法自己在获取的unlabeled数据中找到有趣的东西，如数据中可能包括的结构或模型。比如clustering（聚类）算法，找到数据中可以聚类的集合。e.g.新闻信息的聚类，DNA信息的聚类，市场中对用户进行分组聚类。此外，还有异常检测（anomaly detection）算法（用于检测交易是否正常等）和降维（dimensionality reduction）算法（用于压缩数据集）等、

### 相关术语（terminology）🧐
- 训练集（training set）： 用来训练模型的数据
- 输入变量x（input variable）
- 输出变量y（ouput/target variable）
- (x，y): 表示单个样本   （x^(i)^,y^(i)^) 即第i个样本
- m：表示训练集的大小
- $f$： 即用监督算法得到的计算模型 用来预测结果
- $\hat{y}$： 即在给定输入下模型得到的预测结果
- 模型参数（parameter）： 训练中可能不断改变的数值 用来构建模型 预测结果

### 线性回归模型
通常在监督学习中通过建立回归模型来解决回归问题，回归模型中有无数多种可能的数字输出（这也是它区别于分类模型的特点）。线性回归模型的目标函数即为简单的线性函数:  
$$f(x) = wx + b$$
可见其尽管很多时候不能得到有效的预测值，但是是一种简单实现的回归模型。

### 代价函数（cost function）
容易想到在“暂时”得到模型（参数是暂定的）后需要对模型进行评估，其中一种重要标准就是代价函数，单变量下的标准代价函数（方差代价函数）是：
$$J(w,b) = \frac{1}{2m} \sum_{i=1}^{m} ({\hat{y}}^i - y^i) ^2  ，即$$
$$J(w,b) = \frac{1}{2m} \sum_{i=1}^{m} (f(x^i) - y^i) ^2  $$
其中系数2是方便后续的计算。这是最常见的代价函数，也十分有用。